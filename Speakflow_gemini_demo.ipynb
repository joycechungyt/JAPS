{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmlQHyos6uQ/32n11m1rwa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joycechungyt/JAPS/blob/main/Speakflow_gemini_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SpeakFlow - an AI language app\n",
        "#User will practice conversations with an AI in different role playing scenarios\n",
        "#goal is to improve english through conversations where you feel uncomfortable doing it with a real person\n",
        "#AI will adjust its responses to let you practice & improve more aspects of your english\n",
        "#you can track your progress through the AI generated evaluation of your performance & estimation of your learning, and recommended learning plan."
      ],
      "metadata": {
        "id": "Btj193KgYpzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#when the app is opened, the ai looks at the data in the rolling window to gauge our history.\n",
        "#so no resetting of memory occurs."
      ],
      "metadata": {
        "id": "qs40olddpore"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1. User Profiles\n",
        "# This feature is needed for user onboarding and registration and will need to include the option to sign up via Google and social media accounts. This feature will consist of personal information as well as privacy settings."
      ],
      "metadata": {
        "id": "d9sGUopHWz6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import texttospeech\n",
        "\n",
        "def synthesize_text(text, output_file):\n",
        "    client = texttospeech.TextToSpeechClient()\n",
        "    synthesis_input = texttospeech.SynthesisInput(text=text)\n",
        "    voice = texttospeech.VoiceSelectionParams(\n",
        "        language_code='en-US', ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL\n",
        "    )\n",
        "    audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)\n",
        "    response = client.synthesize_speech(\n",
        "        input=synthesis_input, voice=voice, audio_config=audio_config\n",
        "    )\n",
        "    with open(output_file, 'wb') as out:\n",
        "        out.write(response.audio_content)"
      ],
      "metadata": {
        "id": "AmsosFWoX8Lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Client-side voice recognition functionality in React Native\n",
        "\n",
        "import Voice from 'react-native-voice';\n",
        "\n",
        "// Start voice recognition\n",
        "const startListening = () => {\n",
        "  Voice.start('en-US');\n",
        "}\n",
        "\n",
        "// Listen to voice events\n",
        "Voice.onSpeechPartialResults = (e) => {\n",
        "  const partialTranscript = e.value[0];\n",
        "  // Process partial transcript\n",
        "}\n",
        "\n",
        "// Stop voice recognition\n",
        "const stopListening = () => {\n",
        "  Voice.stop();\n",
        "}\n",
        "\n",
        "#when we're speaking, bot should listen\n",
        "#when we stop speaking, bot should process what we said."
      ],
      "metadata": {
        "id": "nnmJcE1UYFYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Chatbot w/ Voice Recognition\n",
        "\n",
        "# An absolute necessity for a functioning language learning app is a 24/7 multilingual chatbot embedded with speech recognition capabilities.\n",
        "# As mentioned, this is not just for teaching purposes but also for improving the app's performance via machine learning.\n",
        "\n",
        "#build a langchain chatbot compatible with gemini pro"
      ],
      "metadata": {
        "id": "H4OpvWLcXoP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a multi-threaded implementation for continuous listening and transcription\n",
        "\n",
        "#microphone needs to be constantly turned on and the bot listens to our input,\n",
        "#so that the bot can respond to our speech right away and it's more natural\n",
        "#we can use multi-threaded async functions & also run this on the cloud.\n",
        "\n",
        "import threading\n",
        "import queue\n",
        "\n",
        "# Create a queue to store transcriptions\n",
        "transcription_queue = queue.Queue()\n",
        "\n",
        "# Example function to listen to audio and perform transcription\n",
        "def listen_and_transcribe():\n",
        "    while True:\n",
        "        # Listen to audio and perform transcription\n",
        "        audio = listen_audio()  # Replace with your audio listening logic\n",
        "        transcription = transcribe_audio(audio)  # Replace with your audio transcription logic\n",
        "\n",
        "        # Put the transcription on the queue\n",
        "        transcription_queue.put(transcription)\n",
        "\n",
        "# Example function to process transcriptions and provide responses\n",
        "def process_transcriptions():\n",
        "    while True:\n",
        "        # Get the transcription from the queue\n",
        "        transcription = transcription_queue.get()\n",
        "\n",
        "        # Process the transcription and provide a response\n",
        "        response = generate_response(transcription)  # Replace with your response generation logic\n",
        "        print(response)  # Replace with your desired response handling (e.g., sending to frontend)\n",
        "\n",
        "        # Mark the transcription as processed\n",
        "        transcription_queue.task_done()\n",
        "\n",
        "# Start the listening and transcription thread\n",
        "listen_thread = threading.Thread(target=listen_and_transcribe)\n",
        "listen_thread.daemon = True\n",
        "listen_thread.start()\n",
        "\n",
        "# Start the processing thread\n",
        "process_thread = threading.Thread(target=process_transcriptions)\n",
        "process_thread.daemon = True\n",
        "process_thread.start()\n",
        "\n",
        "# Main thread can continue with other operations or tasks\n",
        "while True:\n",
        "    # Perform any other operations or tasks\n",
        "    pass"
      ],
      "metadata": {
        "id": "hb0-Il0Fl48R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Language Course Conversations & Levels\n",
        "# These features will test a user's language level and standard to provide them with suitable conversations and goals to hit. It should also include personalization elements allowing users to plan their unique learning path (eg. what type of conversation they want to have)."
      ],
      "metadata": {
        "id": "8NXnrA-HW6S0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_proficiency(user_responses):\n",
        "    # Evaluate user responses and assign a proficiency level\n",
        "    # based on your defined grading criteria\n",
        "    proficiency_level = \"Intermediate\"  # Example proficiency level\n",
        "\n",
        "    return proficiency_level"
      ],
      "metadata": {
        "id": "X0wUPliTX8nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prompt generation - eg. you are a professor, student, waitress..."
      ],
      "metadata": {
        "id": "Wl9EJsOUQ8bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#user's journey / choice of prompts should be stored in a rolling window\n",
        "#the prompt difficulty should be based on previous responses and conversations, eg. moving forward in difficulty level each time.\n",
        "#ai will re-test people on mistakes\n",
        "#the length of the AI conversation should be easier for people of low level english proficiency\n",
        "\n",
        "#noSQL database can be used to store summaries of previous converations with the User and AI. (eg. in 300 words)"
      ],
      "metadata": {
        "id": "280Y0qrDc5N0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import json\n",
        "\n",
        "# Example command to send data to the frontend\n",
        "def send_data_to_frontend(data):\n",
        "    # Convert the data to JSON format\n",
        "    json_data = json.dumps(data)\n",
        "    # Send the JSON data to the frontend using your chosen method (e.g., websockets, HTTP API, etc.)\n",
        "    # Implementation details depend on your frontend framework or library\n",
        "\n",
        "def generate_lesson_plan(proficiency_level, user_analysis):\n",
        "    conversation_scenarios = {\n",
        "        \"Beginner\": [\n",
        "            {\n",
        "                \"scenario\": \"At a coffee shop\",\n",
        "                \"prompts\": [\n",
        "                    \"Ordering a coffee and a pastry\",\n",
        "                    \"Asking for the Wi-Fi password\",\n",
        "                    \"Making small talk with the barista\"\n",
        "                ],\n",
        "                \"background_image\": \"coffee_shop.jpg\"  # Add the corresponding background image for each scenario\n",
        "            },\n",
        "            {\n",
        "                \"scenario\": \"Inquiring about directions\",\n",
        "                \"prompts\": [\n",
        "                    \"Asking for directions to a nearby landmark\",\n",
        "                    \"Requesting clarification on the directions\",\n",
        "                    \"Thanking the person for their help\"\n",
        "                ],\n",
        "                \"background_image\": \"directions.jpg\"  # Add the corresponding background image for each scenario\n",
        "            },\n",
        "            # Add more beginner scenarios and prompts\n",
        "        ],\n",
        "        \"Intermediate\": [\n",
        "            {\n",
        "                \"scenario\": \"Discussing a movie or book\",\n",
        "                \"prompts\": [\n",
        "                    \"Sharing your opinion on a recent movie or book\",\n",
        "                    \"Describing the plot and characters\",\n",
        "                    \"Asking the other person for recommendations\"\n",
        "                ],\n",
        "                \"background_image\": \"movie_book.jpg\"  # Add the corresponding background image for each scenario\n",
        "            },\n",
        "            {\n",
        "                \"scenario\": \"Planning a weekend trip\",\n",
        "                \"prompts\": [\n",
        "                    \"Discussing possible destinations and activities\",\n",
        "                    \"Making suggestions and expressing preferences\",\n",
        "                    \"Negotiating and finalizing the plan\"\n",
        "                ],\n",
        "                \"background_image\": \"weekend_trip.jpg\"  # Add the corresponding background image for each scenario\n",
        "            },\n",
        "            # Add more intermediate scenarios and prompts\n",
        "        ],\n",
        "        \"Advanced\": [\n",
        "            {\n",
        "                \"scenario\": \"Debating a current issue\",\n",
        "                \"prompts\": [\n",
        "                    \"Presenting arguments and counterarguments\",\n",
        "                    \"Expressing opinions and supporting them with evidence\",\n",
        "                    \"Engaging in a respectful and constructive debate\"\n",
        "                ],\n",
        "                \"background_image\": \"debate.jpg\"  # Add the corresponding background image for each scenario\n",
        "            },\n",
        "            {\n",
        "                \"scenario\": \"Negotiating a business deal\",\n",
        "                \"prompts\": [\n",
        "                    \"Discussing terms and conditions\",\n",
        "                    \"Making offers and counteroffers\",\n",
        "                    \"Reaching a mutually beneficial agreement\"\n",
        "                ],\n",
        "                \"background_image\": \"business_deal.jpg\"  # Add the corresponding background image for each scenario\n",
        "            },\n",
        "            # Add more advanced scenarios and prompts\n",
        "            #for new scenarios, we can use stable diffusion to generate new backgrounds on the fly.\n",
        "        ],\n",
        "    }\n",
        "\n",
        "    if proficiency_level in conversation_scenarios:\n",
        "        scenarios = conversation_scenarios[proficiency_level]\n",
        "        selected_scenario = random.choice(scenarios)\n",
        "        conversation_plan = {\n",
        "            \"scenario\": selected_scenario[\"scenario\"],\n",
        "            \"prompts\": selected_scenario[\"prompts\"]\n",
        "        }\n",
        "\n",
        "        # Send the background image data to the frontend\n",
        "        background_image = selected_scenario[\"background_image\"]\n",
        "        send_data_to_frontend({\"background_image\": background_image})\n",
        "    else:\n",
        "        conversation_plan = None\n",
        "\n",
        "    # Additional processing based on user analysis\n",
        "    if user_analysis[\"grammatical_errors\"] > 0.7:\n",
        "        # Modify the prompts or provide additional exercises targeting grammatical errors\n",
        "        pass\n",
        "\n",
        "    if user_analysis[\"filler_words\"] > 0.5:\n",
        "        # Provide exercises or tips to reduce filler words\n",
        "        pass\n",
        "\n",
        "    # Adjust the difficulty based on vocabulary complexity, intonation, etc.\n",
        "\n",
        "    return conversation_plan"
      ],
      "metadata": {
        "id": "OklEU4OlYD7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import React from 'react';\n",
        "import { Text, TouchableOpacity } from 'react-native';\n",
        "\n",
        "const RoleplayConversation = ({ character, conversationText }) => {\n",
        "  const handleConversationClick = () => {\n",
        "    // Perform actions when conversation is clicked\n",
        "  };\n",
        "\n",
        "  return (\n",
        "    <TouchableOpacity onPress={handleConversationClick}>\n",
        "      <Text>{character}: {conversationText}</Text>\n",
        "    </TouchableOpacity>\n",
        "  );\n",
        "};"
      ],
      "metadata": {
        "id": "vEAQH5REdpcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def track_progress(user_responses):\n",
        "    # Track user's progress and performance\n",
        "    # based on their responses and interactions\n",
        "    # Generate recommendations for further learning\n",
        "    recommendations = [\"Here are some more recommendations for further learning based on your progress and performance:\"]\n",
        "\n",
        "    if user_responses.get(\"accuracy\") < 0.7:\n",
        "        recommendations.append(\"Focus on improving accuracy by practicing pronunciation and grammar.\")\n",
        "\n",
        "    if user_responses.get(\"fluency\") < 0.7:\n",
        "        recommendations.append(\"Work on improving fluency by practicing speaking at a natural pace.\")\n",
        "\n",
        "    if user_responses.get(\"vocab\") < 0.7:\n",
        "        recommendations.append(\"Expand your vocabulary by reading and listening to English materials.\")\n",
        "\n",
        "    # Add more recommendations based on user's performance\n",
        "\n",
        "    return recommendations"
      ],
      "metadata": {
        "id": "3Xx05dp5YI2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import React, { useEffect, useRef } from 'react';\n",
        "import Chart from 'chart.js';\n",
        "\n",
        "const ProficiencyChart = ({ proficiencyData }) => {\n",
        "  const chartRef = useRef(null);\n",
        "\n",
        "  useEffect(() => {\n",
        "    const chartData = {\n",
        "      labels: ['Strengths', 'Weaknesses', 'Intermediate'],\n",
        "      datasets: [\n",
        "        {\n",
        "          label: 'Proficiency Levels',\n",
        "          data: proficiencyData,\n",
        "          backgroundColor: [\n",
        "            'rgba(75, 192, 192, 0.2)', // Strengths color\n",
        "            'rgba(255, 99, 132, 0.2)', // Weaknesses color\n",
        "            'rgba(255, 205, 86, 0.2)' // Intermediate color\n",
        "          ],\n",
        "          borderColor: [\n",
        "            'rgba(75, 192, 192, 1)',\n",
        "            'rgba(255, 99, 132, 1)',\n",
        "            'rgba(255, 205, 86, 1)'\n",
        "          ],\n",
        "          borderWidth: 1,\n",
        "        },\n",
        "      ],\n",
        "    };\n",
        "\n",
        "    const chartOptions = {\n",
        "      responsive: true,\n",
        "      scales: {\n",
        "        y: {\n",
        "          beginAtZero: true,\n",
        "          max: 100,\n",
        "        },\n",
        "      },\n",
        "    };\n",
        "\n",
        "    const ctx = chartRef.current.getContext('2d');\n",
        "    new Chart(ctx, {\n",
        "      type: 'bar',\n",
        "      data: chartData,\n",
        "      options: chartOptions,\n",
        "    });\n",
        "  }, [proficiencyData]);\n",
        "\n",
        "  return <canvas ref={chartRef} />;\n",
        "};"
      ],
      "metadata": {
        "id": "4seE43_nYdym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "const proficiencyData = [80, 50, 70]; // Example proficiency data\n",
        "\n",
        "function App() {\n",
        "  return (\n",
        "    <div>\n",
        "      <h1>Proficiency Chart</h1>\n",
        "      <ProficiencyChart proficiencyData={proficiencyData} />\n",
        "    </div>\n",
        "  );\n",
        "}"
      ],
      "metadata": {
        "id": "ylbCA7P9YfXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this will be a mobile application\n",
        "#we will write the front end with web supported library, and connect the backend with APIs.\n",
        "#write the API in fastAPI and host it using uvicorn\n",
        "#backend code is exactly the same"
      ],
      "metadata": {
        "id": "JqLqXMZne9Yz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}